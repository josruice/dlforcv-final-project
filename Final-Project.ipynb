{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frictionless Product Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Author:** Jose Vicente Ruiz Cepeda (jr3660)\n",
    "- **Course:** COMS W 4995 - Deep Learning for Computer Vision\n",
    "- **Assignment**: Final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain some of the context of the problem here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras # Keras 1.2.2 assumed.\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Required to avoid errors with the images.\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES = {\n",
    "    0: 'photo',\n",
    "    1: 'electronics',\n",
    "    2: 'events',\n",
    "    3: 'instruments',\n",
    "    4: 'tools',\n",
    "    5: 'sports',\n",
    "    6: 'caravans',\n",
    "    7: 'others'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I - Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = './data/train'\n",
    "validation_data_dir = './data/validation'\n",
    "test_data_dir = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categorizer:\n",
    "    def __init__(self, num_classes, num_dense_layer_units=512, dropout=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dense_layer_units = num_dense_layer_units\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def build_model(self, ImagenetModel=ResNet50, verbose=False):\n",
    "        # Keras models are functions, not classes, so we have to check which one is it like this.\n",
    "        if ImagenetModel.func_name == 'InceptionV3' or ImagenetModel.func_name == 'Xception':\n",
    "            self.img_width, self.img_height = 299, 299\n",
    "        else:\n",
    "            self.img_width, self.img_height = 224, 224\n",
    "\n",
    "        # First, let's load the model with ImageNet weights and without the top layer.\n",
    "        # This will take some time the first time, since the weights have to be downloaded.\n",
    "        model = ImagenetModel(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(self.img_width, self.img_height, 3)\n",
    "        )\n",
    "\n",
    "        #Â Now, let's create the top layers adapted to our problem. For that we use the\n",
    "        # Functional API of Keras. (https://keras.io/getting-started/functional-api-guide/)\n",
    "        x = model.output\n",
    "        x = Flatten(input_shape=model.output_shape[1:])(x)\n",
    "        x = Dense(self.num_dense_layer_units, activation='relu')(x)\n",
    "        x = Dropout(self.dropout)(x)\n",
    "        preds = Dense(self.num_classes, activation='softmax')(x)\n",
    "        self.num_top_layers = 4\n",
    "\n",
    "        # Combine both models to get the final one.\n",
    "        self.model = Model(model.input, preds)\n",
    "\n",
    "        if verbose:\n",
    "            self.model.summary()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def compile_model(self, optimizer=optimizers.Adam(lr=0.001)):\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def fine_tune(self,\n",
    "                  class_names,\n",
    "                  train_data_dir,\n",
    "                  validation_data_dir,\n",
    "                  batch_size=16,\n",
    "                  num_only_top_epochs=10,\n",
    "                  num_whole_model_epochs=40):\n",
    "        \n",
    "        # Augmentation configurations for training and validation.\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "        validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # Build the generators.\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=batch_size,\n",
    "            classes=class_names,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        validation_generator = validation_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=batch_size,\n",
    "            classes=class_names,\n",
    "            class_mode='categorical')\n",
    "        \n",
    "        # Freeze everything except the top layers, before training.\n",
    "        for layer in self.model.layers[:-self.num_top_layers]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        self.model.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=train_generator.n,\n",
    "            nb_epoch=num_only_top_epochs,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=validation_generator.n\n",
    "        )\n",
    "        \n",
    "        # Unfreeze everything and train for some more epochs.\n",
    "        for layer in self.model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "        self.model.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=train_generator.n,\n",
    "            nb_epoch=num_whole_model_epochs,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=validation_generator.n\n",
    "        )\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizer = Categorizer(len(CLASS_NAMES)). \\\n",
    "    build_model(Xception). \\\n",
    "    compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorizer.fine_tune(\n",
    "    CLASS_NAMES.values(),\n",
    "    train_data_dir,\n",
    "    validation_data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = '/Users/Josevi/product_images/photo/9760-1.jpg'\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(mpimg.imread(img_path))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "preds = model.predict(x)\n",
    "print preds\n",
    "#print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_sample(X, y, prediction=-1):\n",
    "    im = X\n",
    "    print y\n",
    "    #y = np.flip(y, axis=0)\n",
    "    y_label = class_name[np.nonzero(y)[0][0]]\n",
    "    plt.imshow(im)\n",
    "    if prediction >= 0:\n",
    "        plt.title(\"Class = %s, Predict = %s\" % (y_label, class_name[prediction]))\n",
    "    else:\n",
    "        plt.title(\"Class = %s\" % (y_label))\n",
    "\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for X_batch, Y_batch in train_generator:\n",
    "    for i in range(len(Y_batch)):\n",
    "        show_sample(X_batch[i, :, :, :], Y_batch[i])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
